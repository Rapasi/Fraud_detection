{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa72edd-500f-4fdd-9a8e-765f00dec679",
   "metadata": {},
   "source": [
    "# Tässä pyritään luomaan malli, joka pystyy tunnistamaan luottokorttimaksujen joukosta petokset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14748bac-b35d-4bac-a155-a59e7afd135c",
   "metadata": {},
   "source": [
    "### Tarvittavat kirjastot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cde806b-02eb-4e63-a987-35516433b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras import metrics, models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b855d-9a5e-4d8d-bc57-42ca2399502f",
   "metadata": {},
   "source": [
    "### Avataan datasetti csv-tiedostosta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c255f812-ecee-427d-b408-6165c1bc526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data=pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "577c84c7-b97d-445f-9cc3-ee1184203742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa06ad6b-84fe-42b3-a59e-d9029e602061",
   "metadata": {},
   "source": [
    "#### Normalisoidaan arvot neuroverkkoa varten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187a1a9a-b037-4a3b-af67-bedef0397a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data_norm=(credit_data-credit_data.mean())/credit_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ec4d60-fb78-489b-87d3-e1028bc3379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data_norm.iloc[:,-1:]=credit_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7cffa8f-86ae-47b8-b736-cf9f1fb6db5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.996580</td>\n",
       "      <td>-0.694241</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672771</td>\n",
       "      <td>0.973364</td>\n",
       "      <td>-0.245116</td>\n",
       "      <td>0.347067</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.331127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330891</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.996580</td>\n",
       "      <td>0.608495</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316522</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>-0.232494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307376</td>\n",
       "      <td>-0.880075</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561130</td>\n",
       "      <td>0.320693</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044607</td>\n",
       "      <td>-0.342474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.996558</td>\n",
       "      <td>-0.693499</td>\n",
       "      <td>-0.811576</td>\n",
       "      <td>1.169466</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364571</td>\n",
       "      <td>1.351451</td>\n",
       "      <td>0.639775</td>\n",
       "      <td>0.207372</td>\n",
       "      <td>-1.378673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337631</td>\n",
       "      <td>1.063356</td>\n",
       "      <td>1.456317</td>\n",
       "      <td>-1.138090</td>\n",
       "      <td>-0.628536</td>\n",
       "      <td>-0.288446</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>1.160684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.996558</td>\n",
       "      <td>-0.493324</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182514</td>\n",
       "      <td>-0.609726</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936148</td>\n",
       "      <td>0.192070</td>\n",
       "      <td>0.316017</td>\n",
       "      <td>-1.262501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304776</td>\n",
       "      <td>-1.941024</td>\n",
       "      <td>1.241902</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186188</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.996537</td>\n",
       "      <td>-0.591329</td>\n",
       "      <td>0.531540</td>\n",
       "      <td>1.021410</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071998</td>\n",
       "      <td>0.479301</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>0.744325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>1.100009</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395201</td>\n",
       "      <td>1.041609</td>\n",
       "      <td>0.543619</td>\n",
       "      <td>0.651815</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>1.641929</td>\n",
       "      <td>-6.065831</td>\n",
       "      <td>6.099275</td>\n",
       "      <td>-6.486233</td>\n",
       "      <td>-1.459638</td>\n",
       "      <td>-3.886604</td>\n",
       "      <td>-1.956687</td>\n",
       "      <td>-3.975621</td>\n",
       "      <td>6.116562</td>\n",
       "      <td>1.742556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290602</td>\n",
       "      <td>0.154146</td>\n",
       "      <td>1.624571</td>\n",
       "      <td>-0.840999</td>\n",
       "      <td>2.756316</td>\n",
       "      <td>0.518499</td>\n",
       "      <td>2.337897</td>\n",
       "      <td>2.495525</td>\n",
       "      <td>-0.350150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>1.641950</td>\n",
       "      <td>-0.374121</td>\n",
       "      <td>-0.033356</td>\n",
       "      <td>1.342142</td>\n",
       "      <td>-0.521651</td>\n",
       "      <td>0.629039</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>0.019667</td>\n",
       "      <td>0.246886</td>\n",
       "      <td>0.532298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291625</td>\n",
       "      <td>1.273779</td>\n",
       "      <td>0.019958</td>\n",
       "      <td>-1.677917</td>\n",
       "      <td>-1.163724</td>\n",
       "      <td>-0.819645</td>\n",
       "      <td>0.169641</td>\n",
       "      <td>-0.162163</td>\n",
       "      <td>-0.254116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.641971</td>\n",
       "      <td>0.980022</td>\n",
       "      <td>-0.182433</td>\n",
       "      <td>-2.143201</td>\n",
       "      <td>-0.393983</td>\n",
       "      <td>1.905830</td>\n",
       "      <td>2.275258</td>\n",
       "      <td>-0.239939</td>\n",
       "      <td>0.593139</td>\n",
       "      <td>0.393630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315912</td>\n",
       "      <td>0.796786</td>\n",
       "      <td>-0.060053</td>\n",
       "      <td>1.056942</td>\n",
       "      <td>0.509796</td>\n",
       "      <td>-0.181181</td>\n",
       "      <td>0.011037</td>\n",
       "      <td>-0.080467</td>\n",
       "      <td>-0.081839</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>1.641971</td>\n",
       "      <td>-0.122755</td>\n",
       "      <td>0.321250</td>\n",
       "      <td>0.463319</td>\n",
       "      <td>0.487192</td>\n",
       "      <td>-0.273836</td>\n",
       "      <td>0.468154</td>\n",
       "      <td>-0.554671</td>\n",
       "      <td>0.568630</td>\n",
       "      <td>0.356886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>1.102449</td>\n",
       "      <td>-0.261503</td>\n",
       "      <td>0.203427</td>\n",
       "      <td>-1.091853</td>\n",
       "      <td>1.133633</td>\n",
       "      <td>0.269604</td>\n",
       "      <td>0.316686</td>\n",
       "      <td>-0.313248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>1.642055</td>\n",
       "      <td>-0.272330</td>\n",
       "      <td>-0.114899</td>\n",
       "      <td>0.463865</td>\n",
       "      <td>-0.357569</td>\n",
       "      <td>-0.009089</td>\n",
       "      <td>-0.487601</td>\n",
       "      <td>1.274767</td>\n",
       "      <td>-0.347176</td>\n",
       "      <td>0.442532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355410</td>\n",
       "      <td>0.886147</td>\n",
       "      <td>0.603364</td>\n",
       "      <td>0.014526</td>\n",
       "      <td>-0.908630</td>\n",
       "      <td>-1.696850</td>\n",
       "      <td>-0.005984</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.514354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0      -1.996580 -0.694241 -0.044075  1.672771  0.973364 -0.245116  0.347067   \n",
       "1      -1.996580  0.608495  0.161176  0.109797  0.316522  0.043483 -0.061820   \n",
       "2      -1.996558 -0.693499 -0.811576  1.169466  0.268231 -0.364571  1.351451   \n",
       "3      -1.996558 -0.493324 -0.112169  1.182514 -0.609726 -0.007469  0.936148   \n",
       "4      -1.996537 -0.591329  0.531540  1.021410  0.284655 -0.295015  0.071998   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  1.641929 -6.065831  6.099275 -6.486233 -1.459638 -3.886604 -1.956687   \n",
       "284803  1.641950 -0.374121 -0.033356  1.342142 -0.521651  0.629039  0.794444   \n",
       "284804  1.641971  0.980022 -0.182433 -2.143201 -0.393983  1.905830  2.275258   \n",
       "284805  1.641971 -0.122755  0.321250  0.463319  0.487192 -0.273836  0.468154   \n",
       "284806  1.642055 -0.272330 -0.114899  0.463865 -0.357569 -0.009089 -0.487601   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0       0.193679  0.082637  0.331127  ... -0.024923  0.382854 -0.176911   \n",
       "1      -0.063700  0.071253 -0.232494  ... -0.307376 -0.880075  0.162201   \n",
       "2       0.639775  0.207372 -1.378673  ...  0.337631  1.063356  1.456317   \n",
       "3       0.192070  0.316017 -1.262501  ... -0.147443  0.007267 -0.304776   \n",
       "4       0.479301 -0.226510  0.744325  ... -0.012839  1.100009 -0.220123   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "284802 -3.975621  6.116562  1.742556  ...  0.290602  0.154146  1.624571   \n",
       "284803  0.019667  0.246886  0.532298  ...  0.291625  1.273779  0.019958   \n",
       "284804 -0.239939  0.593139  0.393630  ...  0.315912  0.796786 -0.060053   \n",
       "284805 -0.554671  0.568630  0.356886  ...  0.361111  1.102449 -0.261503   \n",
       "284806  1.274767 -0.347176  0.442532  ...  0.355410  0.886147  0.603364   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  Class  \n",
       "0       0.110507  0.246585 -0.392170  0.330891 -0.063781  0.244964      0  \n",
       "1      -0.561130  0.320693  0.261069 -0.022256  0.044607 -0.342474      0  \n",
       "2      -1.138090 -0.628536 -0.288446 -0.137137 -0.181021  1.160684      0  \n",
       "3      -1.941024  1.241902 -0.460217  0.155396  0.186188  0.140534      0  \n",
       "4       0.233250 -0.395201  1.041609  0.543619  0.651815 -0.073403      0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "284802 -0.840999  2.756316  0.518499  2.337897  2.495525 -0.350150      0  \n",
       "284803 -1.677917 -1.163724 -0.819645  0.169641 -0.162163 -0.254116      0  \n",
       "284804  1.056942  0.509796 -0.181181  0.011037 -0.080467 -0.081839      0  \n",
       "284805  0.203427 -1.091853  1.133633  0.269604  0.316686 -0.313248      0  \n",
       "284806  0.014526 -0.908630 -1.696850 -0.005984  0.041350  0.514354      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c912147-23f5-4fbd-84a9-e9dc3325625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e42cf81-e442-49ef-b5e2-95c6cce3a2d0",
   "metadata": {},
   "source": [
    "#### 284807:sta datapisteestä ainoastaan 492 on petoksia. Tämä on tärkeä huomio ja on otettava huomioon mallia luodessa. Muuten epätasapaino luokkien välillä tekee mallista täysin toimimattoman. Tärkeintä on pyrkiä löytämään kaikki petokset mahdollisimman suurella tarkkuudella. Tämän vuoksi myös tavallisia siirtoja tullaan todennäköisesti tunnistamaan petoksiksi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e88dc0-44e5-4306-b6dd-f82535d03445",
   "metadata": {},
   "source": [
    "### Tarkistetaan sarakkeiden datatyypit. Kaikki sarakkeet ovat jo valmiiksi numeerisia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670a57de-b7eb-4ad5-bafb-f04965736ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32498bde-35ef-4004-8702-022ee6c0e185",
   "metadata": {},
   "source": [
    "### Jaetaan data koulutus-, validointi- ja testisetteihin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f4ab68-fc5b-46c0-9a84-1cdde87e305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(credit_data_norm, test_size=0.1,random_state=312)\n",
    "train, validation = train_test_split(train, test_size=0.3,random_state=312)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52610503-d03b-4c8f-b0d3-f3c45f484d96",
   "metadata": {},
   "source": [
    "### Erotetaan luokat dataseteistä. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe2e7a65-b050-4861-b580-bfe8fd3cfe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target=train.pop('Class')\n",
    "validation_target=validation.pop('Class')\n",
    "test_target=test.pop('Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d597509-ebe6-4046-96b0-9d8ed7bf81db",
   "metadata": {},
   "source": [
    "### Tarkistetaan, että kaikista seteistä löytyy petoksiksi luokiteltuja datapisteitä. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d4ae331-bc45-496b-9093-58076a1ff459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    179128\n",
       "1       300\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c31bab6f-8a05-48a0-a69a-310449ec97cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    76756\n",
       "1      142\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ede090e6-ef3a-4dbd-97a4-fbc627e7077e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28431\n",
       "1       50\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91cc82a-daff-4615-82d0-df671dd0aaff",
   "metadata": {},
   "source": [
    "### Tarkkuus on erittäin huono mittari mallien toiminnan mittaamiseen tässä tapauksessa.\n",
    "- Petoksia on niin vähähn, että arvaamalla aina ei petosta, saavutettaisiin lähes 100 % tarkkuus. \n",
    "- Käytetään siis vääriä ja oikeita positiivisia sekä negatiivisia havaintoja mittaavia funktioita tulosten arvioimiseen.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6bd796-299d-4b4b-baef-8282fbd64b6f",
   "metadata": {},
   "source": [
    "### Asetetaan lisäksi class_weight argumentti, jonka myötä yhtä **ei** petokseksi luokiteltua datapistettä kohti ajetaan petokseksi luokiteltuja datapisteiotä useita kertoja. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce902cb2-f939-409b-af48-39668966549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 16:37:48.766677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 16:37:48.794980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 16:37:48.795165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 16:37:48.796305: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 16:37:48.797444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 16:37:48.797599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 16:37:48.797717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 16:37:49.154967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 16:37:49.155124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 16:37:49.155249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 16:37:49.155358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7405 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "METRICS= [\n",
    "    metrics.FalseNegatives(name=\"fn\"),\n",
    "    metrics.FalsePositives(name=\"fp\"),\n",
    "    metrics.TrueNegatives(name=\"tn\"),\n",
    "    metrics.TruePositives(name=\"tp\"),\n",
    "    metrics.Precision(name=\"precision\"),\n",
    "    metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "class_weights = {0: 1.,\n",
    "                1: 200.}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892c49d-c7ad-47b1-b015-53f5ca6af928",
   "metadata": {},
   "source": [
    "### Rakennetaan hyvin perinteinen neuroverkko ja kokeillaan eri parametreja mahdollisimman hyvien tulosten aikaansaamiseksi. Viimeisen kerroksen aktivaatiofunktion täytyy tässä tapauksessa olla sigmoid, sillä kyseessä on binäärinen luokittelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06dce04d-11d1-4425-832c-28f1969b842f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               3968      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,609\n",
      "Trainable params: 20,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu',input_shape=(30,)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e77fbb-63bb-4946-9a05-4317cd5e1cfc",
   "metadata": {},
   "source": [
    "### Konfiguroidaan malli koulutusta varten. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9fed41c-1060-47ab-beb5-d02eebed64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=METRICS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3c2c0-fa79-415f-9014-19b9a3b311d4",
   "metadata": {},
   "source": [
    "### Koulutetaan malli. Validoidaan mallia jokaisen koulutuskierroksen jälkeen validointidataan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a46ad318-221a-418c-8d66-eefbb56435a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  62/2804 [..............................] - ETA: 7s - loss: 0.8601 - fn: 4.0000 - fp: 19.0000 - tn: 3945.0000 - tp: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 16:37:50.794562: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2804/2804 [==============================] - 10s 3ms/step - loss: 0.2681 - fn: 52.0000 - fp: 1807.0000 - tn: 177321.0000 - tp: 248.0000 - precision: 0.1207 - recall: 0.8267 - val_loss: 0.0547 - val_fn: 12.0000 - val_fp: 605.0000 - val_tn: 76151.0000 - val_tp: 130.0000 - val_precision: 0.1769 - val_recall: 0.9155\n",
      "Epoch 2/10\n",
      "2804/2804 [==============================] - 8s 3ms/step - loss: 0.1728 - fn: 39.0000 - fp: 2126.0000 - tn: 177002.0000 - tp: 261.0000 - precision: 0.1093 - recall: 0.8700 - val_loss: 0.0435 - val_fn: 11.0000 - val_fp: 722.0000 - val_tn: 76034.0000 - val_tp: 131.0000 - val_precision: 0.1536 - val_recall: 0.9225\n",
      "Epoch 3/10\n",
      "2804/2804 [==============================] - 9s 3ms/step - loss: 0.1595 - fn: 39.0000 - fp: 2052.0000 - tn: 177076.0000 - tp: 261.0000 - precision: 0.1128 - recall: 0.8700 - val_loss: 0.0479 - val_fn: 11.0000 - val_fp: 772.0000 - val_tn: 75984.0000 - val_tp: 131.0000 - val_precision: 0.1451 - val_recall: 0.9225\n",
      "Epoch 4/10\n",
      "2804/2804 [==============================] - 9s 3ms/step - loss: 0.1332 - fn: 31.0000 - fp: 2158.0000 - tn: 176970.0000 - tp: 269.0000 - precision: 0.1108 - recall: 0.8967 - val_loss: 0.0814 - val_fn: 12.0000 - val_fp: 528.0000 - val_tn: 76228.0000 - val_tp: 130.0000 - val_precision: 0.1976 - val_recall: 0.9155\n",
      "Epoch 5/10\n",
      "2804/2804 [==============================] - 9s 3ms/step - loss: 0.1188 - fn: 28.0000 - fp: 1908.0000 - tn: 177220.0000 - tp: 272.0000 - precision: 0.1248 - recall: 0.9067 - val_loss: 0.0260 - val_fn: 11.0000 - val_fp: 418.0000 - val_tn: 76338.0000 - val_tp: 131.0000 - val_precision: 0.2386 - val_recall: 0.9225\n",
      "Epoch 6/10\n",
      "2804/2804 [==============================] - 9s 3ms/step - loss: 0.1393 - fn: 30.0000 - fp: 2253.0000 - tn: 176875.0000 - tp: 270.0000 - precision: 0.1070 - recall: 0.9000 - val_loss: 0.0236 - val_fn: 12.0000 - val_fp: 374.0000 - val_tn: 76382.0000 - val_tp: 130.0000 - val_precision: 0.2579 - val_recall: 0.9155\n",
      "Epoch 7/10\n",
      "2804/2804 [==============================] - 8s 3ms/step - loss: 0.1231 - fn: 27.0000 - fp: 2147.0000 - tn: 176981.0000 - tp: 273.0000 - precision: 0.1128 - recall: 0.9100 - val_loss: 0.0209 - val_fn: 13.0000 - val_fp: 310.0000 - val_tn: 76446.0000 - val_tp: 129.0000 - val_precision: 0.2938 - val_recall: 0.9085\n",
      "Epoch 8/10\n",
      "2804/2804 [==============================] - 9s 3ms/step - loss: 0.1288 - fn: 28.0000 - fp: 2958.0000 - tn: 176170.0000 - tp: 272.0000 - precision: 0.0842 - recall: 0.9067 - val_loss: 0.0928 - val_fn: 9.0000 - val_fp: 2309.0000 - val_tn: 74447.0000 - val_tp: 133.0000 - val_precision: 0.0545 - val_recall: 0.9366\n",
      "Epoch 9/10\n",
      "2804/2804 [==============================] - 9s 3ms/step - loss: 0.1158 - fn: 24.0000 - fp: 2592.0000 - tn: 176536.0000 - tp: 276.0000 - precision: 0.0962 - recall: 0.9200 - val_loss: 0.0165 - val_fn: 15.0000 - val_fp: 296.0000 - val_tn: 76460.0000 - val_tp: 127.0000 - val_precision: 0.3002 - val_recall: 0.8944\n",
      "Epoch 10/10\n",
      "2804/2804 [==============================] - 9s 3ms/step - loss: 0.1295 - fn: 21.0000 - fp: 2735.0000 - tn: 176393.0000 - tp: 279.0000 - precision: 0.0926 - recall: 0.9300 - val_loss: 0.0612 - val_fn: 10.0000 - val_fp: 1270.0000 - val_tn: 75486.0000 - val_tp: 132.0000 - val_precision: 0.0942 - val_recall: 0.9296\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x=train,\n",
    "                  y=train_target,\n",
    "                  epochs=10,\n",
    "                  verbose=1,\n",
    "                  batch_size=64,\n",
    "                  class_weight=class_weights,\n",
    "                  validation_data=(validation,validation_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c46640-7c27-46e0-b696-943de27b7dc1",
   "metadata": {},
   "source": [
    "### Testataan mallia aiemmin näkemättömällä datalla. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1b87e29-01f3-4c4c-9fc3-1b9abbe4d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 2s 2ms/step - loss: 0.0609 - fn: 4.0000 - fp: 452.0000 - tn: 27979.0000 - tp: 46.0000 - precision: 0.0924 - recall: 0.9200\n",
      "[0.06089625135064125, 4.0, 452.0, 27979.0, 46.0, 0.09236947447061539, 0.9200000166893005]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.evaluate(test,test_target,batch_size=32)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4123e78-df77-47f0-ae97-261e779350ce",
   "metadata": {},
   "source": [
    "### Malli tunnisti oikein petoksiksi 46 kpl havaintoja. 4 petosta jäi tunnistamatta ja lisäksi väärin petoksiksi tunnistettiin 452 kpl havaintoja.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fdeac-b2f3-4074-bc0e-0e0c6bdbde99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
